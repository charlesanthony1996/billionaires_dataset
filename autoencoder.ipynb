{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ndo4ERqnwQOU"
   },
   "source": [
    "# Exercise: Generative Models\n",
    "\n",
    "\n",
    "## Goal of this exercise\n",
    "\n",
    "This exercise is all about Autoencoders. You will learn how to train them, visualize their latent space and use them for image completion: \n",
    "The exercise is an adaptation of https://www.tensorflow.org/tutorials/generative/autoencoder\n",
    "\n",
    "\n",
    "You can execute individual code blocks by pressing SHIFT+Enter consecutively.\n",
    "\n",
    "You can trigger auto completion with TABULATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfNT-mlFwxVM"
   },
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox, TextArea\n",
    "import umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Task 1: Load the dataset\n",
    "We want to train the autoencoder on the Fashion MNIST dataset. Therefore we need to load it first.\n",
    "x_train and x_test are the images of the dataset and y_train and y_test are the labels as integers.\n",
    "The mappings to the actual class names is provided by the variable class_names\n",
    "\n",
    "**tasks:** \n",
    "- print the shape of both x_train, y_train, x_test, y_test and explain what each dimension represents.\n",
    "- use matplotlib to display the first image of the training set and also print its class name in the title of the figure (plt.title())."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**your answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZm503-I_tji"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "class_names = [\"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEdCXSwCoKok"
   },
   "source": [
    "## Task 2: Basic Autoencoder\n",
    "\n",
    "In the below cells you find everything to define the Autoencoder, train on the dataset and visualize the training results.\n",
    "We are also training to variants of the autoencoder, where we use 1. latent space of 2, 2. latent space of 64\n",
    "**TODO:** execute all the cells below to train both models and visualize the results, then answer the following questions in the markdown cell below:\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. What is the purpose of the encoder?\n",
    "2. What is the purpose of decoder?\n",
    "3. What type of loss are we using and what does it do?\n",
    "4. What is the role of the latent space and why does it lead to different results in the visualizations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MUxidpyChjX"
   },
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim, shape):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.shape = shape\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(tf.math.reduce_prod(shape), activation='sigmoid'),\n",
    "      layers.Reshape(shape)\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "\n",
    "shape = x_test.shape[1:]\n",
    "\n",
    "latent_dim64 = 64\n",
    "autoencoder64 = Autoencoder(latent_dim64, shape)\n",
    "\n",
    "latent_dim2 = 2\n",
    "autoencoder2 = Autoencoder(latent_dim2, shape)\n",
    "\n",
    "latent_dim_miss = 64\n",
    "autoencoder_miss = Autoencoder(latent_dim_miss, shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9I1JlqEIDCI4"
   },
   "outputs": [],
   "source": [
    "autoencoder64.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "autoencoder2.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1RI9OfHDBsK"
   },
   "outputs": [],
   "source": [
    "autoencoder64.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAM1QBhtoC-n"
   },
   "source": [
    "Now that the model is trained, let's test it by encoding and decoding images from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pbr5WCj7FQUi"
   },
   "outputs": [],
   "source": [
    "encoded_imgs64 = autoencoder64.encoder(x_test).numpy()\n",
    "decoded_imgs64 = autoencoder64.decoder(encoded_imgs64).numpy()\n",
    "\n",
    "encoded_imgs2 = autoencoder2.encoder(x_test).numpy()\n",
    "decoded_imgs2 = autoencoder2.decoder(encoded_imgs2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4LlDOS6FUA1"
   },
   "outputs": [],
   "source": [
    "# visualization of the results\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1)\n",
    "  plt.imshow(x_test[i])\n",
    "  plt.title(\"original\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  plt.imshow(decoded_imgs2[i])\n",
    "  plt.title(\"reconstructed\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.suptitle('Latent Space = 2')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, n, i + 1)\n",
    "  plt.imshow(x_test[i])\n",
    "  plt.title(\"original\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  plt.imshow(decoded_imgs64[i])\n",
    "  plt.title(\"reconstructed\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.suptitle('Latent Space = 64')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Latent Space Visualization\n",
    "\n",
    "Now we would like to visualize the latent space of the two Autoencoder results.\n",
    "For the autoencoder with the 2 dimensional latent space we can directly plot the results in a scatterplot.\n",
    "When using a latent space of 64, we first need to apply dimensionality reduction to reduce the amount of features to a number of 2.\n",
    "\n",
    "**TODO:**\n",
    "1. execute the cell below and visualize the dim=2 latent space\n",
    "2. use umap to reduce the embedding space from 64 to 2 and visualize the latent space in the same way\n",
    "3. answer the following Question\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "1. What are your observations when comparing both visualizations of the latent space?\n",
    "2. Which latent space shows better clusters and why is that the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answers here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization latent space dim=2\n",
    "\n",
    "# select a random amount of points to avoid plotting all points\n",
    "idx = np.random.choice(len(x_test), 1000)\n",
    "\n",
    "images = x_test[idx]\n",
    "encodings = encoded_imgs2[idx]\n",
    "labels = y_test[idx]\n",
    "\n",
    "\n",
    "print(encodings.shape)\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.set_title(\"latent space autoencoder dim 2\")\n",
    "plt.scatter(encodings[:, 0], encodings[:, 1], c=labels,cmap = \"viridis\")\n",
    "plt.colorbar()\n",
    "for i in range(10):\n",
    "    class_center = np.mean(encodings[labels == i], axis=0)\n",
    "    text = TextArea('{} ({})'.format(class_names[i], i))\n",
    "    ab = AnnotationBbox(text, class_center, xycoords='data', frameon=True)\n",
    "    ax.add_artist(ab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4gv6G8PoRQE"
   },
   "source": [
    "## Task 4 Learning to fill missing patches\n",
    "\n",
    "Before we used the autoencoder for reconstructing the same image.\n",
    "Now we would like to use the exact same architecture for filling in missing data (image inpainting).\n",
    "Specifically, we want to use the fashion mnist images as the input, but we manipulate the image data in a way that for each image \n",
    "a 10 x 10 pixel block in the middle is missing (values set to zero)\n",
    "\n",
    "**TODO:**\n",
    "1. you now need create copies of x_train and x_test where a pixel block of 10 x 10 in the middle of each image is set to 0.\n",
    "2. name these two copies x_train_m and x_test_m\n",
    "3. Now follow the structure from Task 2 and train the autoencoder on filling in the missing pixel blocks\n",
    "4. Visualize and the results and discuss them in the markdown cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autoencoder.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
